This thesis deals with the problem of script and language identification in document images and scene images. As the world is becoming more and more multilingual, the documents and the scene-images has started to contain the text from different languages. Hence, an individual \textsc{ocr} specific for any language would not be able to correctly recognize the text from other languages, be it document image texts or scene-image texts.

We propose two methods for script and language identification, which can be used in multilingual settings. First, we have addressed the problem of script identification in the wild. To this end, we have established a baseline for the end-to-end script identification pipeline for scene text and shown that simple mid-level features can achieve reasonably high performance for this task. We have also introduced a robust Indian Language Scene Text (\textsc{ILST}) dataset, which can be used in future for research in multilingual environment. To show the generality of our method, we also compare our method on the dataset, containing 10 scripts, which has been introduced in Video Script Identification Competition held at \textsc{icdar} 2015. The dataset is composed of images from news videos of various Indian languages. Our method achieves 96.70\% for script identification in all the ten scripts and clearly outperform two methods in the competition namely, \textsc{c-dac} and \textsc{cuk}. Moreover, our results are marginally superior to \textsc{hust}, \textsc{cvc-1}, \textsc{cvc-2} and comparable to the deep learning based best performing method by Google.

Second, we present a recurrent neural network based script and language identification for document images at words and line levels. This work comprises of two components. First component computes the sequential feature from an unsegmented word image. The second component, \textsc{lstm} is used to classify the incoming word image into its corresponding  scripts and languages. Also, experiments on a public dataset show that even with naive features, \textsc{rnn}s achieves good if not better results than the state-of-the-art method. We also observe that, \textsc{rnn}s are able to characterize the statistical distribution of features computed over vertical segments. To show the generality of our method, we also compare our method with the method proposed in ~\cite{Pati} on the reported dataset. Our method that uses a naive features yield results comparable to those that are evolved over years of research. In addition, our method uses a multi-class classifier as compared to hierarchical classifier used in ~\cite{Pati}.

Script identification in scene-texts being a fairly new area has not been explored highly. One can explore different features, hand-crafted or otherwise, and different classifiers other than \textsc{svm}, like recurrent neural networks, convolutional neural networks etc. As a future work, we plan to extend the \textsc{ilst} dataset to 10 popular scripts used in India and explore the usage of multiple cues as aid to our script identifier, such as location of the image and neighboring texts.

Using recurrent neural networks for document and script identification in document images is one step towards a fully automated multilingual \textsc{ocr}s. Presently, separate \textsc{ocr}s are needed to be developed for different script and languages using recurrent neural networks~\cite{PraveenDAS}. Instead of developing several \textsc{ocr}s, one can explore the idea of developing a single multilingual ~\textsc{ocr} with an script and language identification module integrated. This multilingual ~\textsc{ocr} should be able to recognize the document images from all the possible languages or scripts. We can also explore the generality of proposed method in Chapter~\ref{ch:chap4} by performing the script and language identification on handwritten document images. Through the experiments done above, we also observe that, \textsc{rnn}s are capable of characterizing the statistical distribution of features computed over vertical segments. We hope that this can help in other forms of recognition free tasks in document image understanding.




